{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyvision as pv\n",
    "import time\n",
    "import pyvision.face.CascadeDetector as cd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    detector = cd.CascadeDetector()\n",
    "    \n",
    "    cam = pv.Webcam()\n",
    "    time.sleep(1)\n",
    "    for frame in cam:\n",
    "        rects = detector(frame)\n",
    "        for rect in rects:\n",
    "            frame.annotateRect(rect)\n",
    "        frame.show(delay=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyvision as pv\n",
    "import pyvision.face.CascadeDetector as cd\n",
    "import pyvision.face.FilterEyeLocator as ed\n",
    "\n",
    "face_detect = cd.CascadeDetector()\n",
    "eye_detect = ed.FilterEyeLocator()\n",
    "\n",
    "im = pv.Image(\"face2.jpg\",bw_annotate=True)\n",
    "for frame in cam:\n",
    "    faces = face_detect(frame)\n",
    "    eyes = eye_detect(frame,faces)\n",
    "    for face,eye1,eye2 in eyes:\n",
    "#         frame.annotateRect(rect)\n",
    "        frame.annotatePolygon(face.asPolygon(),width=4)\n",
    "        frame.annotatePoints([eye1,eye2])\n",
    "        frame.show(delay=30)\n",
    "faces = face_detect(im)\n",
    "eyes = eye_detect(im,faces)\n",
    "\n",
    "for face,eye1,eye2 in eyes:\n",
    "    im.annotatePolygon(face.asPolygon(),width=4)\n",
    "    im.annotatePoints([eye1,eye2])\n",
    "    \n",
    "im.show(delay=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyvision as pv\n",
    "import cv2.cv as cv\n",
    "import time\n",
    "\n",
    "cam = pv.Webcam()\n",
    "time.sleep(2)\n",
    "\n",
    "imgBuffer = pv.ImageBuffer(N=20)\n",
    "\n",
    "montage = pv.VideoMontage({1:cam, 2:cam}, (1,2),(640,480))\n",
    "montage.play(delay=33, window=\"Demo\")\n",
    "\n",
    "# for frame in cam:\n",
    "#     imgBuffer.add(frame)\n",
    "#     imgBuffer.show(N=20,delay=20)\n",
    "# #     montage = imgBuffer.asMontage(layout=(2,5))\n",
    "# #     montage.show(window=\"Demo\")\n",
    "# #     if imgBuffer.isFull():\n",
    "# #         montage = pv.ImageMontage({1:frame, 2:imgBuffer.getLast()}, (1,2))\n",
    "# # #         montage.show(window=\"Demo\")\n",
    "# #         montage.show(delay=33)\n",
    "    \n",
    "# cv.DestroyWindow(\"Demo\")\n",
    "# montage = imgBuffer.asMontage(layout=(5,5))\n",
    "# montage.show(window=\"Demo\")\n",
    "# # montage = pv.VideoMontage( {1:vid, 2:vid.}, (1,2), (133,100))\n",
    "# # montage.play(delay=33, window=\"Demo\")\n",
    "# # cv.DestroyWindow(\"Demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__iter__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_pauseAndPlay', 'cv_capture', 'flipped', 'grab', 'next', 'play', 'query', 'resize', 'retrieve', 'size']\n",
      "Help on Webcam in module pyvision.types.Video object:\n",
      "\n",
      "class Webcam(VideoInterface)\n",
      " |  # Video capture is an alterative for windows http://videocapture.sourceforge.net/\n",
      " |  # An option for linux http://code.google.com/p/python-video4linux2/\n",
      " |  # On linux it may be possible to use something like v4lctl to capture in a separate process.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Webcam\n",
      " |      VideoInterface\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, camera_num=0, size=(640, 480), flipped=False)\n",
      " |      Web camera interface for cameras attached to your computer via USB or built-in.\n",
      " |      For IP/network cameras, use the Video object instead.\n",
      " |      @param camera_num: The camera index. Usually 0 if you only have a single webcam\n",
      " |      on your computer. See the OpenCV highgui documentation for details.\n",
      " |      @param flipped: Set to true if camera is installed upside-down.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator for this video\n",
      " |  \n",
      " |  grab(self)\n",
      " |  \n",
      " |  query(self)\n",
      " |      The returned image also include a field named orig_frame which returns \n",
      " |      the original image returned before rescaling.\n",
      " |      \n",
      " |      @returns: the frame rescaled to a given size.\n",
      " |  \n",
      " |  retrieve(self)\n",
      " |      The returned image also include a field named orig_frame which returns \n",
      " |      the original image returned before rescaling.\n",
      " |      \n",
      " |      @returns: the frame rescaled to a given size.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from VideoInterface:\n",
      " |  \n",
      " |  next(self)\n",
      " |      The next method calls self.query(), so it is common to most video sources\n",
      " |      and may not need to be overridden.\n",
      " |      @return: The next frame in the sequence, or raise StopIteration if done.\n",
      " |  \n",
      " |  play(self, window='Input', pos=None, delay=20, annotate=True, imageBuffer=None, startframe=0, endframe=None, onNewFrame=None, **kwargs)\n",
      " |      Plays the video, calling the onNewFrame function after loading each\n",
      " |       frame from the video. The user may interrupt video playback by\n",
      " |       hitting (sometimes repeatedly) the spacebar, upon which they are\n",
      " |       given a text menu in the console to abort program, quit playback,\n",
      " |       continue playback, or step to the next frame.\n",
      " |      @param window: The window name used to display the video. If None,\n",
      " |      then the video won't be shown, but onNewFrame will be called at\n",
      " |      each frame.\n",
      " |      @param pos: A tuple (x,y) where the output window should be located\n",
      " |      on the users screen. None indicates default openCV positioning algorithm\n",
      " |      will be used.\n",
      " |      @param delay: The delay in ms between window updates. This allows the user\n",
      " |      to control the playback frame rate. A value of 0 indicates that the video\n",
      " |      will wait for keyboard input prior to advancing to the next frame. This\n",
      " |      delay is used by the pauseAndPlay interface, so it will affect the rate\n",
      " |      at which onNewFrame is called as well.\n",
      " |      @param annotate: If True, the image will be annotated with the frame number\n",
      " |      in the upper left corner. Set false for no frame number annotation.\n",
      " |      @param imageBuffer: An optional pyvision ImageBuffer object to contain the\n",
      " |      most recent frames. This is useful if a buffer is required for background\n",
      " |      subtraction, for example. The buffer contents is directly modified each\n",
      " |      time a new image is captured from the video, and a reference to the buffer\n",
      " |      is passed to the onNewFrame function (defined below).\n",
      " |      @param startframe: If > 0, then the video will cue itself by quickly fast-forwarding\n",
      " |      to the desired start frame before any images are shown. During the cueing process,\n",
      " |      any _onNewFrame function callbacks (or VideoStreamProcessor objects) will NOT be\n",
      " |      activated.\n",
      " |      @param endframe: If not None, then the playback will end after this frame has\n",
      " |      been processed.\n",
      " |      @param onNewFrame: A python callable object (function) with a\n",
      " |      signature of 'foo( pvImage, frameNum, key=None, buffer=None )', where key is\n",
      " |      the key pressed by the user (if any) during the pauseAndPlay interface, and\n",
      " |      buffer is a reference to the optional image buffer provided to the play method.\n",
      " |      @param kwargs: Optional keyword arguments that should be passed\n",
      " |      onto the onNewFrame function.\n",
      " |      @return: The final frame number of the video, or the frame number at which\n",
      " |      the user terminated playback using the 'q'uit option.\n",
      " |  \n",
      " |  resize(self, frame)\n",
      " |      Used to resize the source frame to the desired output size. This\n",
      " |      method is common to most sources and may not need to be overridden.\n",
      " |      The query() method will typically call this resize() method prior\n",
      " |      to returning the captured image.\n",
      " |      @param frame: An openCV image (note: not a pyvision image)\n",
      " |      @return: An openCV image with the new dimensions\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from VideoInterface:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyvision as pv\n",
    "import time\n",
    "vsp_resizer = pv.ResizerVSP(window=\"Resized Image\",new_size=(120,120))\n",
    "vsp_disp = pv.FrameNumberVSP(window=\"Display\", nextModule=vsp_resizer)\n",
    "vid = pv.Webcam()\n",
    "\n",
    "print dir(vid)\n",
    "\n",
    "help(vid)\n",
    "# time.sleep(1)\n",
    "# vid.play(window=None, delay=25, onNewFrame=vsp_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
